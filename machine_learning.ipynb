{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a2c580",
   "metadata": {},
   "source": [
    "Machine Learning Deep Dive\\\n",
    "Prepare By: Ejaz-ur-Rehman\\\n",
    "Date: 20-07-2025\\\n",
    "Email ID: ijazfinance@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d11b5",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "- Machine learning is a subset of artificial intelligence that involves training algorithms to make predictions or decisions based on data.\n",
    "- Machine learning allows machine to learn and make decisions smarlty. \n",
    "- It can learn from teh data, which is already machines have or provided them to proceed with.\n",
    "- It depends upon the type of machine learning. \n",
    "- In machine learning process, we provide Data then we train the model, then we test the model and finally we deploy the model. Further, we can predict from this process to find unkonwn. \n",
    "- There are four major process:\n",
    "  1. Data Preprocessing\n",
    "  2. Learning \n",
    "  3. Predction \n",
    "  4. Decision \n",
    "- Machine learning is used in many applications such as image recognition, speech recognition, natural language processing, and more.\n",
    "- Machine learning, Deep Learning and Generative AI are the sub branches of Artificial Intelligence.\n",
    "- The advance type of AI is ML, advnace type of ML is DL and further advance type of DL is GAI.\n",
    "    - Articial Intelligence: AI, is the ability of a machine to perform tasks that would typically require human intelligence. OR engineering of making intelligent machines and programms on teh basis of the Data. \n",
    "    - Machine Learning: ML, is a subset of AI that involves training algorithms to make predictions or decisions based on data. OR ability to learn withou explicitly programmed.\n",
    "    - Deep Learning: DL, is a subset of ML that involves training algorithms to learn complex patterns in data. OR learning based on deep nural networks.\n",
    "    - Generative AI: GAI, is a subset of DL that involves training algorithms to generate new data that resembles existing data.\n",
    "- what is Data Science: Data Science is the process of extracting insights and knowledge from data using various techniques and tools. OR process or is a sbset of AI include area of statistics and mathametics, scientific methods to extract menaing and insights from the data.\n",
    "\n",
    "## Types of Machine Learning:\n",
    "- Supervised Learning: In this type of learning, the algorithm is trained on labeled data, where the correct output is already known. Examples are Email Spam Detection: Input (features): Email text, sender, subject line, etc. Output (target variable): Spam or Not Spam. 2. Image Classification: Input (features):Output (label): Spam or Not Spam, Algorithm examples: Naive Bayes, Logistic Regression, SVM.\n",
    "  \n",
    "- Unspervised / Clustering Learning: In this type of learning, the algorithm is trained on unlabeled data, and it must find patterns or structure in the data. Examples are Customer Segmentation, Goal: Group customers based on purchasing behavior, demographics, etc. Algorithm examples: K-Means, Hierarchical Clustering. Use case: Targeted marketing campaigns. Algorithms: K-Means Clustering, DBSCAN, Hierarchical Clustering\n",
    "  \n",
    "- Semisupervised Learning: In this type of learning, the algorithm is trained on a combination of labeled and unlabeled data. Examples are Medical Image Classification, Use case: Classifying X-rays or MRIs as healthy or diseased. Problem: Only a few images are labeled by experts (doctors), while many are unlabeled. Algorithm examples: Self-training, Co-training, Multi-view learning. Use case: Medical diagnosis, diseas\n",
    "Solution: Semi-supervised CNNs learn from a few labeled and many unlabeled images\n",
    "\n",
    "- Reinforcement Learning: In this type of learning, the algorithm learns by interacting with an environment and receiving rewards or penalties for its actions. Examples are Game Playing (Atari, Chess, Go), Use case: AI learns to play and win games. Problem: AI must learn to make decisions based on rewards or penalties. Algorithm examples: Q-learning, SARSA, Deep Q-Networks (DQN). Use case: Robotics, autonomous vehicles, game playing. Algorithms: Q-learning, SARSA, DQN, Policy Gradient Methods. Use case: Robotics, autonomous vehicles, game playing.\n",
    "\n",
    "- Real World Examples of Supervised Machne Learning: \n",
    "\n",
    "| Use Case                              | Description                                                                                            | Algorithm(s) Commonly Used                             |\n",
    "| ------------------------------------- | ------------------------------------------------------------------------------------------------------ | ------------------------------------------------------ |\n",
    "| üìß **Email Spam Detection**           | Classify emails as \"spam\" or \"not spam\" based on past examples                                         | Naive Bayes, Logistic Regression, Random Forest        |\n",
    "| üè• **Medical Diagnosis**              | Predict disease presence (e.g. cancer detection) from patient features like blood test results, X-rays | Support Vector Machines (SVM), Decision Trees          |\n",
    "| üìä **Credit Scoring**                 | Predict whether a customer will default on a loan based on their credit history                        | Logistic Regression, XGBoost                           |\n",
    "| üõí **Customer Churn Prediction**      | Predict if a customer is likely to leave a service                                                     | K-Nearest Neighbors (KNN), Random Forest               |\n",
    "| üöó **Car Price Prediction**           | Predict the price of a car given mileage, brand, and year                                              | Linear Regression, Gradient Boosting                   |\n",
    "| üè† **House Price Prediction**         | Estimate house prices based on features like area, location, rooms                                     | Linear Regression, Decision Trees                      |\n",
    "| üîä **Speech Recognition**             | Convert spoken words into text using labeled voice data                                                | Deep Neural Networks, Recurrent Neural Networks (RNNs) |\n",
    "| üì∑ **Image Classification**           | Classify images into categories (e.g. cat vs dog)                                                      | Convolutional Neural Networks (CNNs)                   |\n",
    "| üí¨ **Sentiment Analysis**             | Predict whether a review is positive or negative                                                       | Naive Bayes, SVM, LSTM (for text data)                 |\n",
    "| üéì **Student Performance Prediction** | Predict students' final grades based on attendance, assignments, etc.                                  | Random Forest, Linear Regression                       |\n",
    "\n",
    "- Common Supervised ML Algorithms:\n",
    "\n",
    "| Algorithm                                      | Type           | Use Cases                                          |\n",
    "| ---------------------------------------------- | -------------- | -------------------------------------------------- |\n",
    "| **Linear Regression**                          | Regression     | Price predictions (e.g., housing, cars)            |\n",
    "| **Logistic Regression**                        | Classification | Binary outcomes like churn or disease presence     |\n",
    "| **Decision Tree**                              | Both           | Interpretable models for classification/regression |\n",
    "| **Random Forest**                              | Both           | Robust ensemble model for various problems         |\n",
    "| **Support Vector Machine (SVM)**               | Classification | Text classification, image recognition             |\n",
    "| **K-Nearest Neighbors (KNN)**                  | Both           | Simple baseline for classification and regression  |\n",
    "| **Naive Bayes**                                | Classification | Spam detection, sentiment analysis                 |\n",
    "| **Gradient Boosting (e.g. XGBoost, LightGBM)** | Both           | High-performance models in Kaggle competitions     |\n",
    "| **Neural Networks (DNNs, CNNs, RNNs)**         | Both           | Used in image, speech, and text applications       |\n",
    "\n",
    "\n",
    "- Real World Examples of Unsupervised Machne Learning: \n",
    "\n",
    "| Use Case                       | Description                                                                                    | Common Algorithms                                                                  |\n",
    "| ------------------------------ | ---------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |\n",
    "| üë• **Customer Segmentation**   | Group customers based on behavior, demographics, or spending patterns to personalize marketing | **K-Means Clustering**, **DBSCAN**, **Hierarchical Clustering**                    |\n",
    "| üõí **Market Basket Analysis**  | Identify associations or frequently bought-together items in retail transactions               | **Apriori**, **FP-Growth (Frequent Pattern Growth)**                               |\n",
    "| üì∏ **Image Compression**       | Reduce dimensions while preserving important information to compress image data                | **PCA (Principal Component Analysis)**, **Autoencoders**                           |\n",
    "| üßæ **Anomaly Detection**       | Identify outliers or unusual data points (e.g., fraud, errors in manufacturing)                | **Isolation Forest**, **One-Class SVM**, **Local Outlier Factor**                  |\n",
    "| üìö **Topic Modeling in Text**  | Discover abstract topics in large sets of documents (e.g., news articles, research papers)     | **LDA (Latent Dirichlet Allocation)**, **NMF (Non-negative Matrix Factorization)** |\n",
    "| üìà **Stock Movement Patterns** | Identify groups of stocks with similar movement or volatility trends                           | **K-Means**, **PCA**                                                               |\n",
    "| üé• **Content Recommendation**  | Suggest content to users by identifying similarity in consumption patterns                     | **Clustering + Collaborative Filtering**, **Matrix Factorization**                 |\n",
    "| üåê **Social Network Analysis** | Detect communities or influencer groups in a social graph                                      | **Spectral Clustering**, **Modularity Optimization**                               |\n",
    "\n",
    "\n",
    "- Popular Unsupervised Learning Algorithms & Their Use:\n",
    "\n",
    "| Algorithm                                     | Type                                     | Used For                                                                  |\n",
    "| --------------------------------------------- | ---------------------------------------- | ------------------------------------------------------------------------- |\n",
    "| **K-Means Clustering**                        | Clustering                               | Grouping similar items or people (e.g., customers, products)              |\n",
    "| **Hierarchical Clustering**                   | Clustering                               | Tree-like grouping (dendrogram) based on similarity                       |\n",
    "| **DBSCAN (Density-Based Spatial Clustering)** | Clustering                               | Grouping data based on density (better for non-spherical data)            |\n",
    "| **PCA (Principal Component Analysis)**        | Dimensionality Reduction                 | Reduce features while retaining variance (e.g., image compression)        |\n",
    "| **t-SNE / UMAP**                              | Dimensionality Reduction & Visualization | Visualize high-dimensional data in 2D or 3D                               |\n",
    "| **LDA (Latent Dirichlet Allocation)**         | Topic Modeling                           | Discover topics in large text datasets                                    |\n",
    "| **Autoencoders (Neural Networks)**            | Feature Learning                         | Dimensionality reduction, anomaly detection                               |\n",
    "| **Isolation Forest**                          | Anomaly Detection                        | Find outliers efficiently in high-dimensional datasets                    |\n",
    "| **One-Class SVM**                             | Anomaly Detection                        | Detect outliers by separating dense normal data from sparse abnormal data |\n",
    "\n",
    "- Semi Supervised Machine Learning Real-World Examples with Algorithm Usage:\n",
    "\n",
    "| Use Case                            | Description                                                                                           | Common Algorithms                                                              |\n",
    "| ----------------------------------- | ----------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ |\n",
    "| üß¨ **Medical Image Classification** | Labeling MRI scans or X-rays requires expert knowledge; train on a few labeled scans + many unlabeled | **Semi-Supervised CNNs**, **Pseudo-Labeling**, **Consistency Regularization**  |\n",
    "| üìù **Document Classification**      | Classify news or legal documents with only a few tagged examples                                      | **Self-training**, **Label Propagation**, **Graph Neural Networks (GNNs)**     |\n",
    "| üßí **Facial Recognition**           | Use a small set of labeled faces and a large set of unknown ones to train face ID models              | **Semi-Supervised GANs**, **Contrastive Learning**, **Autoencoders**           |\n",
    "| üéß **Audio Event Detection**        | Identify sounds (e.g., alarms, speech, nature) with few labeled samples                               | **Ladder Networks**, **Mean Teacher**, **Temporal Ensembling**                 |\n",
    "| üßæ **Sentiment Classification**     | Few labeled reviews, many unlabeled ones for movies, products, etc.                                   | **Text-based Semi-Supervised Transformers**, **Self-training with NLP models** |\n",
    "| üì∏ **Object Detection in Images**   | Annotated images are expensive to label; use unannotated images for learning features                 | **FixMatch**, **Noisy Student**, **SSL YOLO variants**                         |\n",
    "| üë®‚Äçüíª **Spam Filtering**            | Start with few labeled emails and improve the model using a large inbox of unlabeled ones             | **Self-training Naive Bayes**, **Semi-supervised SVMs**                        |\n",
    "\n",
    "\n",
    "- Popular Semi-Supervised Learning Algorithms & Methods:\n",
    "\n",
    "| Algorithm / Method                      | Description                                                                      | Use                                                         |\n",
    "| --------------------------------------- | -------------------------------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| **Self-training**                       | Train model on labeled data ‚Üí use it to label some unlabeled data ‚Üí retrain      | General-purpose method for tabular, text, or image data     |\n",
    "| **Label Propagation / Spreading**       | Graph-based method that propagates labels through data based on similarity       | Used in document classification, social networks            |\n",
    "| **Pseudo-Labeling**                     | Assign temporary labels to unlabeled data using a model's predictions            | Widely used in computer vision tasks                        |\n",
    "| **Ladder Networks**                     | Neural network that combines supervised and unsupervised learning layers         | Excellent for text/audio/image classification               |\n",
    "| **Consistency Regularization**          | Encourages the model to produce consistent predictions under small input changes | Used in image classification (e.g., FixMatch, Mean Teacher) |\n",
    "| **Noisy Student Training**              | Train a student model using noisy data labeled by a teacher model                | Used in large-scale semi-supervised image classification    |\n",
    "| **Semi-Supervised SVM**                 | Modified SVM that uses both labeled and unlabeled data for better margin finding | Suitable for binary classification                          |\n",
    "| **GANs for SSL (e.g., SGAN, MixMatch)** | Use generative models to augment labeled data and improve training               | Common in image generation and classification               |\n",
    "\n",
    "\n",
    "- Reinforcement Machine Learning Real-World Examples with Algorithm Usage:\n",
    "\n",
    "| Use Case                                     | Description                                                                        | Common Algorithms                                                     |\n",
    "| -------------------------------------------- | ---------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| üéÆ **Game Playing (e.g., Chess, Go, Atari)** | Train agents to learn and master games through trial and error                     | **Q-Learning**, **Deep Q-Networks (DQN)**, **AlphaZero**              |\n",
    "| üöó **Autonomous Driving**                    | Train vehicles to navigate environments, avoid obstacles, and follow traffic rules | **Policy Gradient**, **Proximal Policy Optimization (PPO)**, **DDPG** |\n",
    "| üè≠ **Industrial Robotics**                   | Teach robots to pick and place items, weld, or assemble parts                      | **Reinforce**, **Actor-Critic**, **Soft Actor-Critic (SAC)**          |\n",
    "| üìà **Stock Trading Bots**                    | Learn to buy/sell stocks based on market signals for optimal return                | **Q-Learning**, **Deep RL**, **TD Learning**                          |\n",
    "| ü§ñ **Smart Grid Energy Management**          | Optimize when and how to distribute electricity efficiently                        | **DQN**, **Policy Gradient**                                          |\n",
    "| üß† **Personalized Recommendation Engines**   | Learn to suggest products/content by maximizing user engagement                    | **Multi-Armed Bandits**, **Contextual Bandits**, **Deep RL**          |\n",
    "| üß¨ **Healthcare Treatment Planning**         | Suggest treatments based on patient responses to previous treatments               | **Deep Q-Network**, **REINFORCE**                                     |\n",
    "| ‚úàÔ∏è **Flight Control Systems**                | Teach autopilot systems to adapt to weather, routes, and emergencies               | **Model-Based RL**, **TD3 (Twin Delayed DDPG)**                       |\n",
    "\n",
    "\n",
    "- Popular Reinforcement Learning Algorithms:\n",
    "\n",
    "| Algorithm                                     | Type                             | Description                                                      | Common Uses                                |\n",
    "| --------------------------------------------- | -------------------------------- | ---------------------------------------------------------------- | ------------------------------------------ |\n",
    "| **Q-Learning**                                | Value-Based                      | Learns value of actions to find optimal policy                   | Simple games, small environments           |\n",
    "| **Deep Q-Networks (DQN)**                     | Value-Based (Deep Learning)      | Combines Q-learning with neural networks                         | Atari games, simulations                   |\n",
    "| **SARSA**                                     | Value-Based                      | Similar to Q-learning, but learns from the action actually taken | Safer strategies in uncertain environments |\n",
    "| **Policy Gradient (REINFORCE)**               | Policy-Based                     | Directly learns the policy instead of value function             | Continuous control problems                |\n",
    "| **Actor-Critic**                              | Hybrid                           | Learns both policy (actor) and value function (critic)           | Robotics, real-time control                |\n",
    "| **PPO (Proximal Policy Optimization)**        | Policy-Based                     | Stable and efficient version of policy gradient                  | Robotics, self-driving cars                |\n",
    "| **DDPG (Deep Deterministic Policy Gradient)** | Actor-Critic (Continuous Action) | Works well in continuous action spaces                           | Autonomous navigation, industrial control  |\n",
    "| **A3C (Asynchronous Advantage Actor-Critic)** | Actor-Critic                     | Trains multiple agents asynchronously for faster learning        | Multi-agent environments                   |\n",
    "| **TD Learning (Temporal Difference)**         | Value-Based                      | Combines ideas of Monte Carlo and Dynamic Programming            | Forecasting, financial modeling            |\n",
    "\n",
    "\n",
    "- Comparison of Machine Learning Types:\n",
    "\n",
    "| Feature / Criteria         | **Supervised Learning**                                                           | **Unsupervised Learning**                                              | **Semi-Supervised Learning**                                         | **Reinforcement Learning**                                             |\n",
    "| -------------------------- | --------------------------------------------------------------------------------- | ---------------------------------------------------------------------- | -------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n",
    "| **Labeled Data Required?** | ‚úÖ Yes (fully labeled)                                                             | ‚ùå No                                                                   | ‚úÖ‚ùå Yes (a small portion labeled)                                     | ‚ùå Not required (reward signal used instead)                            |\n",
    "| **Goal / Objective**       | Learn to predict output from input                                                | Discover hidden patterns or groupings                                  | Improve prediction using limited labeled data + lots of unlabeled    | Learn optimal action policy through trial and error                    |\n",
    "| **Example Use Cases**      | - Email spam detection  <br> - Loan approval <br> - House price prediction        | - Customer segmentation <br> - Anomaly detection <br> - Topic modeling | - Medical imaging <br> - Text classification <br> - Audio tagging    | - Game AI <br> - Robotics <br> - Self-driving cars <br> - Trading bots |\n",
    "| **Data Type**              | Labeled data (X and Y)                                                            | Unlabeled data (only X)                                                | Small labeled + large unlabeled                                      | State, action, and reward signal                                       |\n",
    "| **Feedback Type**          | Direct (correct answers provided)                                                 | No feedback                                                            | Limited feedback (partial labels)                                    | Delayed (rewards/punishments over time)                                |\n",
    "| **Learning Output**        | Predictive model (e.g., classification or regression)                             | Structure/model of hidden patterns (clusters, features)                | Improved predictive model with few labels                            | Policy or value function for best actions                              |\n",
    "| **Algorithms Used**        | - Linear/Logistic Regression <br> - Decision Tree <br> - SVM <br> - Random Forest | - K-Means <br> - PCA <br> - DBSCAN <br> - Autoencoders                 | - Self-training <br> - Label Propagation <br> - Semi-supervised CNNs | - Q-Learning <br> - DQN <br> - PPO <br> - Actor-Critic                 |\n",
    "| **Strengths**              | Accurate with enough labeled data                                                 | Good for exploration & feature learning                                | Cost-effective when labeling is expensive                            | Learns complex strategies over time                                    |\n",
    "| **Weaknesses**             | Needs lots of labeled data                                                        | Results are harder to validate                                         | Still needs some labeled data; sensitive to initial labels           | Slow convergence, complex, needs lots of interactions                  |\n",
    "| **Evaluation Metrics**     | Accuracy, Precision, Recall, RMSE                                                 | Silhouette Score, Davies-Bouldin Index                                 | Same as supervised + improvement over base supervised model          | Cumulative Reward, Win Rate, Convergence                               |\n",
    "\n",
    "- Types of Supervised Machine Learning:\n",
    "\n",
    "| **Type**              | **Definition**                                                        | **Examples**                                                                                                   | **Common Algorithms**                                                                                                                              |\n",
    "| --------------------- | --------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **1. Classification** | Predicts **categorical** (discrete) labels or classes from input data | - Spam vs. Not Spam<br>- Disease diagnosis (COVID, Diabetes)<br>- Fraud detection<br>- Customer churn (Yes/No) | - Logistic Regression<br>- Decision Trees<br>- Random Forest<br>- Support Vector Machine (SVM)<br>- k-Nearest Neighbors (k-NN)<br>- Naive Bayes    |\n",
    "| **2. Regression**     | Predicts **continuous** (real-valued) output variables                | - Predicting house prices<br>- Forecasting sales<br>- Estimating temperature<br>- Predicting blood pressure    | - Linear Regression<br>- Ridge/Lasso Regression<br>- Decision Tree Regressor<br>- SVR (Support Vector Regression)<br>- Gradient Boosting Regressor |\n",
    "\n",
    "- Key Differences:\n",
    "\n",
    "| Aspect                | **Classification**            | **Regression**          |\n",
    "| --------------------- | ----------------------------- | ----------------------- |\n",
    "| **Output type**       | Discrete labels (classes)     | Continuous values       |\n",
    "| **Loss function**     | Cross-entropy, hinge loss     | Mean Squared Error, MAE |\n",
    "| **Evaluation metric** | Accuracy, Precision, F1-score | RMSE, MAE, R¬≤ Score     |\n",
    "| **Output examples**   | Yes/No, Category A/B/C        | 95.6, \\$204,000, 37.2¬∞C |\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
